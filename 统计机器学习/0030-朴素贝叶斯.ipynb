{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes公式\n",
    "\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "其中，P\\(A\\|B\\)表示的是B发生时，A的条件概率。也叫做A的后验概率.P\\(A\\)表示的是A的先验概率.即不考虑B是否发生。\n",
    "推导过程请见以下公式：\n",
    "$$\n",
    "P(A|B) = \\frac{P(A\\bigcap B)}{P(B)}，P(B|A) = \\frac{P(A\\bigcap B)}{P(A)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型类型\n",
    "\n",
    "生成式模型，是先对$P(x,c)$建模，然后得到$P(c|x)$，c为类别\n",
    "$$\n",
    "P(c|\\mathbf{x}) = \\frac{P(\\mathbf{x}, c)}{P(\\mathbf{x})}\n",
    "$$\n",
    "基于贝叶斯定理，$P(c|\\mathbf{x})$可写为：\n",
    "$$\n",
    "P(c|\\mathbf{x}) = \\frac{P(c) \\cdot P(\\mathbf{x}|c)}{P(\\mathbf{x})}\n",
    "$$\n",
    "其中$P(c)$是类“先验（prior）”概率$P(\\mathbf{x}|c)$是样本$\\mathbf{x}$基于类标记c的类条件概率（class-conditional probability），或称为似然（如垃圾邮件过滤中，$p(\\mathbf{x}|c)$是各分类中，该单词出现的概率，垃圾分类样本可以认为是所有单词），$P(\\mathbf{x})$是用于归一化的\"证据（evidence）\"，对于给定的样本，与分类c无关，所以，只需要考虑$P(c),P(\\mathbf{x}|c))$。\n",
    "\n",
    "$P(c)$表达了样本空间中各类样本所占比例，根据大数定理，只要**训练集包含充足的独立同分布样本**时，$P(c)$可通过各类样本出现的频率来进行估计。\n",
    "\n",
    "对$P(\\mathbf{x}|c)$来说，由于他涉及关于$\\mathbf{x}$所有属性的联合概率，直接根据样本的频率来估计会遇到严重的困难。例如样本d个属性，每个2个值，则有$2^d$个可能性，如果10w个单词构成的样本，远超过样本量。虽然大部分特征在一条原本不出现，但是**未被观察到不代表出现概率为0**，这就为后面MLE，EM讨论奠定基础。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后验概率最大化含义\n",
    "\n",
    "定义损失函数：0-1损失函数\n",
    "\n",
    "期望损失函数（[经验损失函数，期望损失函数，结构损失函数区别](http://blog.csdn.net/liyajuan521/article/details/44565269)）：\n",
    "$$\n",
    "R_{exp}(f)=E[L(Y, f(X))]\n",
    "$$\n",
    "最小化$R_{exp}(f)$， 根据0-1损失函数，相当于最大化概率和：\n",
    "$$\n",
    "f(x)=arg\\underset{y \\in Y}{min}\\sum_{k=1}^{K}L(c_k,y)P(c_k|X=x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "=arg\\underset{y \\in Y}{min}\\sum_{k=1}^{K}P(y\\neq c_k|X=x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "=arg\\underset{y \\in Y}{min}(1 - P(y = c_k|X=x))\n",
    "$$\n",
    "\n",
    "$$\n",
    "=arg\\underset{y \\in Y}{max}P(y=c_k|X=x)\n",
    "$$\n",
    "\n",
    "这样以来，根据期望风险最小化准则就得到了后验概率最大化准则：\n",
    "$$\n",
    "f(x)=arg\\underset{c_k}{max}P(c_k|X=x)\n",
    "$$\n",
    "即朴素贝叶斯法所采用的原理。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 极大似然估计与贝叶斯估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 频率派：极大似然估计（Maximum Likelihood Estimation），简称MLE\n",
    "\n",
    "依据：参数虽然未知，但是是客观存在的即假设$样本独立同分布，且分布已知$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯分类器：假设所有特征独立\n",
    "\n",
    "要点：假设特征独立。不需要考虑是所有特征的联合概率。则：\n",
    "$$\n",
    "P(c|\\mathbf{x}) = \\frac{P(c) \\cdot P(\\mathbf{x}|c)}{P(\\mathbf{x})}=\\frac{P(c)}{P(\\mathbf{x})}\\prod_{i=1}^{d}P(x_i|c)\n",
    "$$\n",
    "同理，可以消去$P(\\mathbf{x})$。令$D_c$表示第c类样本组成的集合，$P(c)=\\frac{|D_c|}{|D|}$，离散属性，$D_{c,x_i}$表示$D_c$中第$i$个属性取值为$x_i$的原本组成的集合，$\\hat{P}(x_i|c) = \\frac{|D_{c,x_i}|}{|D_c|}$，对连续特征，考虑概率密度函数（假设$p(x_i|c) \\sim N(u_{c,i},{\\sigma }^2_{c,i})$）\n",
    "$$\n",
    "f(x)=\\frac{1}{\\sqrt{{2\\pi}}\\times\\sigma_{c,i}}e^{-\\frac{(x-\\mu_{c,i})^2}{2 \\cdot \\sigma^2_{c,i}}^2}\n",
    "$$\n",
    "有个明显的问题，如果某个特征在某个类别c中未出现，则计算出来的概率=0,需要做修正：\n",
    "\n",
    "<font color=red>拉普拉斯修正</font>\n",
    "$$\n",
    "{\\hat{P}(c)=\\frac{|D_C| + 1}{|D| + N}\\\\\n",
    "\\hat{P}(x_i|c) = \\frac{|D_{c,x_i}| + 1}{|D_c|+N_i}\n",
    "}\n",
    "$$\n",
    "其中，N表示为训练集D中可能的类别数，$N_i$表示第$i$个特征可能的取值数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 半朴素贝叶斯分类器\n",
    "\n",
    "解决完全独立假设，太复杂，参考：周志华版本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 贝叶斯网络、Gibbs采样、马尔可夫链\n",
    "\n",
    "**贝叶斯网络构建概念认识**\n",
    "\n",
    "第一步，构建道德图（第一步所有V型结构父节点增加一条无向边；第二步将所有有向边改为无向边）\n",
    "\n",
    "第二步：找出所有条件独立关系\n",
    "\n",
    "**算法构建**\n",
    "\n",
    "评分搜索，MDL准则（最小描述长度准则），损失函数\n",
    "$$\n",
    "{s(B|D) = f(\\theta)|B| - LL(B|D)\\\\\n",
    "LL(B|D) = \\sum_{i=1}^{m}logP_b(x_i)\n",
    "}\n",
    "$$\n",
    "其中$B=<G,\\Theta>$在D上的评分函数，D为训练集。$|B|$为贝叶斯网络节点数$f(\\theta)$描述每个参数$\\theta$所需编码数。。损失函数第一项是计算贝叶斯网络所需要的编码位数，第二项计算的是$B$所对应的概率分布$P_B$对$D$描述有多好\n",
    "\n",
    "$AIC$（$f(\\theta)=1$）,$BIC$（$f(\\theta)=\\frac{1}{2}log\\ m$）\n",
    "\n",
    "从所有网络结构空间搜索最优贝叶斯网结构是一个NP难题。要想快速求解，2个办法：\n",
    "\n",
    "一、 贪心法，从如从某个网络结构出发，每次调整一条边，直到收敛\n",
    "\n",
    "二、 控制网络结构为树形等\n",
    "\n",
    "**推断：Gibbs抽样**\n",
    "\n",
    "第一步，随机产生一个与证据($E=e$)一致的样本$q^0$,如{色泽，敲声，瓜蒂}\n",
    "\n",
    "然后每一步从当前样本产生下一个，先假设t不样本$q^t=q^{t-1}$，然后对非证据变量逐个采样改变其值。采样概率根据贝叶斯网$B$和其他变量当前取值计算。假设经过$T$次采样得到的与q一致的样本有$n_q$个，则可近似估计后验概率\n",
    "$$\n",
    "P(Q=q|E=e)\\simeq \\frac{n_q}{T}\n",
    "$$\n",
    "实际上，吉不斯采样实在贝叶斯所有变量的联合状态空间与证据$E=e$一致的子空间进行\"随机漫步\"。每一步仅依赖于前一步的状态，这是一个“马尔可夫链”。在一定条件下，无论从什么初始状态，必然收敛到一个平稳过程，马尔可夫链需要很长时间才收敛，而且如果网络出现概率=0或1，则不保证收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn实操\n",
    "\n",
    "实操参考：https://scikit-learn.org/stable/modules/naive_bayes.html，https://sklearn.apachecn.org/docs/master/10.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 75 points : 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
